{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1ec83c6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\Projects\\github\\X_Ray_Classification\n"
     ]
    }
   ],
   "source": [
    "%cd D:\\Projects\\github\\X_Ray_Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f3ec49c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0a149ccb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Image",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Class",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Split",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "resized",
         "rawType": "object",
         "type": "string"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "d562c832-6947-4429-8629-3bc83a72f31a",
       "rows": [
        [
         "0",
         "D:\\Projects\\Github\\X_Ray_Classification\\data\\chest_xray\\chest_xray\\train\\NORMAL\\IM-0115-0001.jpeg",
         "NORMAL",
         "train",
         "data/resized/train_NORMAL_IM-0115-0001.jpeg"
        ],
        [
         "1",
         "D:\\Projects\\Github\\X_Ray_Classification\\data\\chest_xray\\chest_xray\\train\\NORMAL\\IM-0117-0001.jpeg",
         "NORMAL",
         "train",
         "data/resized/train_NORMAL_IM-0117-0001.jpeg"
        ],
        [
         "2",
         "D:\\Projects\\Github\\X_Ray_Classification\\data\\chest_xray\\chest_xray\\train\\NORMAL\\IM-0119-0001.jpeg",
         "NORMAL",
         "train",
         "data/resized/train_NORMAL_IM-0119-0001.jpeg"
        ],
        [
         "3",
         "D:\\Projects\\Github\\X_Ray_Classification\\data\\chest_xray\\chest_xray\\train\\NORMAL\\IM-0122-0001.jpeg",
         "NORMAL",
         "train",
         "data/resized/train_NORMAL_IM-0122-0001.jpeg"
        ],
        [
         "4",
         "D:\\Projects\\Github\\X_Ray_Classification\\data\\chest_xray\\chest_xray\\train\\NORMAL\\IM-0125-0001.jpeg",
         "NORMAL",
         "train",
         "data/resized/train_NORMAL_IM-0125-0001.jpeg"
        ]
       ],
       "shape": {
        "columns": 4,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Image</th>\n",
       "      <th>Class</th>\n",
       "      <th>Split</th>\n",
       "      <th>resized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>D:\\Projects\\Github\\X_Ray_Classification\\data\\c...</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>train</td>\n",
       "      <td>data/resized/train_NORMAL_IM-0115-0001.jpeg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D:\\Projects\\Github\\X_Ray_Classification\\data\\c...</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>train</td>\n",
       "      <td>data/resized/train_NORMAL_IM-0117-0001.jpeg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>D:\\Projects\\Github\\X_Ray_Classification\\data\\c...</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>train</td>\n",
       "      <td>data/resized/train_NORMAL_IM-0119-0001.jpeg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>D:\\Projects\\Github\\X_Ray_Classification\\data\\c...</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>train</td>\n",
       "      <td>data/resized/train_NORMAL_IM-0122-0001.jpeg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>D:\\Projects\\Github\\X_Ray_Classification\\data\\c...</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>train</td>\n",
       "      <td>data/resized/train_NORMAL_IM-0125-0001.jpeg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Image   Class  Split  \\\n",
       "0  D:\\Projects\\Github\\X_Ray_Classification\\data\\c...  NORMAL  train   \n",
       "1  D:\\Projects\\Github\\X_Ray_Classification\\data\\c...  NORMAL  train   \n",
       "2  D:\\Projects\\Github\\X_Ray_Classification\\data\\c...  NORMAL  train   \n",
       "3  D:\\Projects\\Github\\X_Ray_Classification\\data\\c...  NORMAL  train   \n",
       "4  D:\\Projects\\Github\\X_Ray_Classification\\data\\c...  NORMAL  train   \n",
       "\n",
       "                                       resized  \n",
       "0  data/resized/train_NORMAL_IM-0115-0001.jpeg  \n",
       "1  data/resized/train_NORMAL_IM-0117-0001.jpeg  \n",
       "2  data/resized/train_NORMAL_IM-0119-0001.jpeg  \n",
       "3  data/resized/train_NORMAL_IM-0122-0001.jpeg  \n",
       "4  data/resized/train_NORMAL_IM-0125-0001.jpeg  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_map = pd.read_csv(r\"D:\\Projects\\github\\X_Ray_Classification\\data\\chest_xray\\chest_xray\\data_map.csv\")\n",
    "data_map.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6a422f3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3d2d4a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "lbl_encoder = LabelEncoder()\n",
    "data_map[\"clas_enc\"] = lbl_encoder.fit_transform(data_map[\"Class\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aa53ab83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Image",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Class",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Split",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "resized",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "clas_enc",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "5c2f7b6b-f12b-4c42-baa4-807034286739",
       "rows": [
        [
         "0",
         "D:\\Projects\\Github\\X_Ray_Classification\\data\\chest_xray\\chest_xray\\train\\NORMAL\\IM-0115-0001.jpeg",
         "NORMAL",
         "train",
         "data/resized/train_NORMAL_IM-0115-0001.jpeg",
         "0"
        ],
        [
         "1",
         "D:\\Projects\\Github\\X_Ray_Classification\\data\\chest_xray\\chest_xray\\train\\NORMAL\\IM-0117-0001.jpeg",
         "NORMAL",
         "train",
         "data/resized/train_NORMAL_IM-0117-0001.jpeg",
         "0"
        ],
        [
         "2",
         "D:\\Projects\\Github\\X_Ray_Classification\\data\\chest_xray\\chest_xray\\train\\NORMAL\\IM-0119-0001.jpeg",
         "NORMAL",
         "train",
         "data/resized/train_NORMAL_IM-0119-0001.jpeg",
         "0"
        ],
        [
         "3",
         "D:\\Projects\\Github\\X_Ray_Classification\\data\\chest_xray\\chest_xray\\train\\NORMAL\\IM-0122-0001.jpeg",
         "NORMAL",
         "train",
         "data/resized/train_NORMAL_IM-0122-0001.jpeg",
         "0"
        ],
        [
         "4",
         "D:\\Projects\\Github\\X_Ray_Classification\\data\\chest_xray\\chest_xray\\train\\NORMAL\\IM-0125-0001.jpeg",
         "NORMAL",
         "train",
         "data/resized/train_NORMAL_IM-0125-0001.jpeg",
         "0"
        ],
        [
         "5",
         "D:\\Projects\\Github\\X_Ray_Classification\\data\\chest_xray\\chest_xray\\train\\NORMAL\\IM-0127-0001.jpeg",
         "NORMAL",
         "train",
         "data/resized/train_NORMAL_IM-0127-0001.jpeg",
         "0"
        ],
        [
         "6",
         "D:\\Projects\\Github\\X_Ray_Classification\\data\\chest_xray\\chest_xray\\train\\NORMAL\\IM-0128-0001.jpeg",
         "NORMAL",
         "train",
         "data/resized/train_NORMAL_IM-0128-0001.jpeg",
         "0"
        ],
        [
         "7",
         "D:\\Projects\\Github\\X_Ray_Classification\\data\\chest_xray\\chest_xray\\train\\NORMAL\\IM-0129-0001.jpeg",
         "NORMAL",
         "train",
         "data/resized/train_NORMAL_IM-0129-0001.jpeg",
         "0"
        ],
        [
         "8",
         "D:\\Projects\\Github\\X_Ray_Classification\\data\\chest_xray\\chest_xray\\train\\NORMAL\\IM-0131-0001.jpeg",
         "NORMAL",
         "train",
         "data/resized/train_NORMAL_IM-0131-0001.jpeg",
         "0"
        ],
        [
         "9",
         "D:\\Projects\\Github\\X_Ray_Classification\\data\\chest_xray\\chest_xray\\train\\NORMAL\\IM-0133-0001.jpeg",
         "NORMAL",
         "train",
         "data/resized/train_NORMAL_IM-0133-0001.jpeg",
         "0"
        ],
        [
         "10",
         "D:\\Projects\\Github\\X_Ray_Classification\\data\\chest_xray\\chest_xray\\train\\NORMAL\\IM-0135-0001.jpeg",
         "NORMAL",
         "train",
         "data/resized/train_NORMAL_IM-0135-0001.jpeg",
         "0"
        ],
        [
         "11",
         "D:\\Projects\\Github\\X_Ray_Classification\\data\\chest_xray\\chest_xray\\train\\NORMAL\\IM-0137-0001.jpeg",
         "NORMAL",
         "train",
         "data/resized/train_NORMAL_IM-0137-0001.jpeg",
         "0"
        ],
        [
         "12",
         "D:\\Projects\\Github\\X_Ray_Classification\\data\\chest_xray\\chest_xray\\train\\NORMAL\\IM-0140-0001.jpeg",
         "NORMAL",
         "train",
         "data/resized/train_NORMAL_IM-0140-0001.jpeg",
         "0"
        ],
        [
         "13",
         "D:\\Projects\\Github\\X_Ray_Classification\\data\\chest_xray\\chest_xray\\train\\NORMAL\\IM-0141-0001.jpeg",
         "NORMAL",
         "train",
         "data/resized/train_NORMAL_IM-0141-0001.jpeg",
         "0"
        ],
        [
         "14",
         "D:\\Projects\\Github\\X_Ray_Classification\\data\\chest_xray\\chest_xray\\train\\NORMAL\\IM-0143-0001.jpeg",
         "NORMAL",
         "train",
         "data/resized/train_NORMAL_IM-0143-0001.jpeg",
         "0"
        ],
        [
         "15",
         "D:\\Projects\\Github\\X_Ray_Classification\\data\\chest_xray\\chest_xray\\train\\NORMAL\\IM-0145-0001.jpeg",
         "NORMAL",
         "train",
         "data/resized/train_NORMAL_IM-0145-0001.jpeg",
         "0"
        ],
        [
         "16",
         "D:\\Projects\\Github\\X_Ray_Classification\\data\\chest_xray\\chest_xray\\train\\NORMAL\\IM-0147-0001.jpeg",
         "NORMAL",
         "train",
         "data/resized/train_NORMAL_IM-0147-0001.jpeg",
         "0"
        ],
        [
         "17",
         "D:\\Projects\\Github\\X_Ray_Classification\\data\\chest_xray\\chest_xray\\train\\NORMAL\\IM-0149-0001.jpeg",
         "NORMAL",
         "train",
         "data/resized/train_NORMAL_IM-0149-0001.jpeg",
         "0"
        ],
        [
         "18",
         "D:\\Projects\\Github\\X_Ray_Classification\\data\\chest_xray\\chest_xray\\train\\NORMAL\\IM-0151-0001.jpeg",
         "NORMAL",
         "train",
         "data/resized/train_NORMAL_IM-0151-0001.jpeg",
         "0"
        ],
        [
         "19",
         "D:\\Projects\\Github\\X_Ray_Classification\\data\\chest_xray\\chest_xray\\train\\NORMAL\\IM-0152-0001.jpeg",
         "NORMAL",
         "train",
         "data/resized/train_NORMAL_IM-0152-0001.jpeg",
         "0"
        ],
        [
         "20",
         "D:\\Projects\\Github\\X_Ray_Classification\\data\\chest_xray\\chest_xray\\train\\NORMAL\\IM-0154-0001.jpeg",
         "NORMAL",
         "train",
         "data/resized/train_NORMAL_IM-0154-0001.jpeg",
         "0"
        ],
        [
         "21",
         "D:\\Projects\\Github\\X_Ray_Classification\\data\\chest_xray\\chest_xray\\train\\NORMAL\\IM-0156-0001.jpeg",
         "NORMAL",
         "train",
         "data/resized/train_NORMAL_IM-0156-0001.jpeg",
         "0"
        ],
        [
         "22",
         "D:\\Projects\\Github\\X_Ray_Classification\\data\\chest_xray\\chest_xray\\train\\NORMAL\\IM-0158-0001.jpeg",
         "NORMAL",
         "train",
         "data/resized/train_NORMAL_IM-0158-0001.jpeg",
         "0"
        ],
        [
         "23",
         "D:\\Projects\\Github\\X_Ray_Classification\\data\\chest_xray\\chest_xray\\train\\NORMAL\\IM-0160-0001.jpeg",
         "NORMAL",
         "train",
         "data/resized/train_NORMAL_IM-0160-0001.jpeg",
         "0"
        ],
        [
         "24",
         "D:\\Projects\\Github\\X_Ray_Classification\\data\\chest_xray\\chest_xray\\train\\NORMAL\\IM-0162-0001.jpeg",
         "NORMAL",
         "train",
         "data/resized/train_NORMAL_IM-0162-0001.jpeg",
         "0"
        ],
        [
         "25",
         "D:\\Projects\\Github\\X_Ray_Classification\\data\\chest_xray\\chest_xray\\train\\NORMAL\\IM-0164-0001.jpeg",
         "NORMAL",
         "train",
         "data/resized/train_NORMAL_IM-0164-0001.jpeg",
         "0"
        ],
        [
         "26",
         "D:\\Projects\\Github\\X_Ray_Classification\\data\\chest_xray\\chest_xray\\train\\NORMAL\\IM-0166-0001.jpeg",
         "NORMAL",
         "train",
         "data/resized/train_NORMAL_IM-0166-0001.jpeg",
         "0"
        ],
        [
         "27",
         "D:\\Projects\\Github\\X_Ray_Classification\\data\\chest_xray\\chest_xray\\train\\NORMAL\\IM-0168-0001.jpeg",
         "NORMAL",
         "train",
         "data/resized/train_NORMAL_IM-0168-0001.jpeg",
         "0"
        ],
        [
         "28",
         "D:\\Projects\\Github\\X_Ray_Classification\\data\\chest_xray\\chest_xray\\train\\NORMAL\\IM-0170-0001.jpeg",
         "NORMAL",
         "train",
         "data/resized/train_NORMAL_IM-0170-0001.jpeg",
         "0"
        ],
        [
         "29",
         "D:\\Projects\\Github\\X_Ray_Classification\\data\\chest_xray\\chest_xray\\train\\NORMAL\\IM-0172-0001.jpeg",
         "NORMAL",
         "train",
         "data/resized/train_NORMAL_IM-0172-0001.jpeg",
         "0"
        ],
        [
         "30",
         "D:\\Projects\\Github\\X_Ray_Classification\\data\\chest_xray\\chest_xray\\train\\NORMAL\\IM-0176-0001.jpeg",
         "NORMAL",
         "train",
         "data/resized/train_NORMAL_IM-0176-0001.jpeg",
         "0"
        ],
        [
         "31",
         "D:\\Projects\\Github\\X_Ray_Classification\\data\\chest_xray\\chest_xray\\train\\NORMAL\\IM-0177-0001.jpeg",
         "NORMAL",
         "train",
         "data/resized/train_NORMAL_IM-0177-0001.jpeg",
         "0"
        ],
        [
         "32",
         "D:\\Projects\\Github\\X_Ray_Classification\\data\\chest_xray\\chest_xray\\train\\NORMAL\\IM-0178-0001.jpeg",
         "NORMAL",
         "train",
         "data/resized/train_NORMAL_IM-0178-0001.jpeg",
         "0"
        ],
        [
         "33",
         "D:\\Projects\\Github\\X_Ray_Classification\\data\\chest_xray\\chest_xray\\train\\NORMAL\\IM-0180-0001.jpeg",
         "NORMAL",
         "train",
         "data/resized/train_NORMAL_IM-0180-0001.jpeg",
         "0"
        ],
        [
         "34",
         "D:\\Projects\\Github\\X_Ray_Classification\\data\\chest_xray\\chest_xray\\train\\NORMAL\\IM-0182-0001.jpeg",
         "NORMAL",
         "train",
         "data/resized/train_NORMAL_IM-0182-0001.jpeg",
         "0"
        ],
        [
         "35",
         "D:\\Projects\\Github\\X_Ray_Classification\\data\\chest_xray\\chest_xray\\train\\NORMAL\\IM-0183-0001.jpeg",
         "NORMAL",
         "train",
         "data/resized/train_NORMAL_IM-0183-0001.jpeg",
         "0"
        ],
        [
         "36",
         "D:\\Projects\\Github\\X_Ray_Classification\\data\\chest_xray\\chest_xray\\train\\NORMAL\\IM-0185-0001.jpeg",
         "NORMAL",
         "train",
         "data/resized/train_NORMAL_IM-0185-0001.jpeg",
         "0"
        ],
        [
         "37",
         "D:\\Projects\\Github\\X_Ray_Classification\\data\\chest_xray\\chest_xray\\train\\NORMAL\\IM-0187-0001.jpeg",
         "NORMAL",
         "train",
         "data/resized/train_NORMAL_IM-0187-0001.jpeg",
         "0"
        ],
        [
         "38",
         "D:\\Projects\\Github\\X_Ray_Classification\\data\\chest_xray\\chest_xray\\train\\NORMAL\\IM-0189-0001.jpeg",
         "NORMAL",
         "train",
         "data/resized/train_NORMAL_IM-0189-0001.jpeg",
         "0"
        ],
        [
         "39",
         "D:\\Projects\\Github\\X_Ray_Classification\\data\\chest_xray\\chest_xray\\train\\NORMAL\\IM-0191-0001.jpeg",
         "NORMAL",
         "train",
         "data/resized/train_NORMAL_IM-0191-0001.jpeg",
         "0"
        ],
        [
         "40",
         "D:\\Projects\\Github\\X_Ray_Classification\\data\\chest_xray\\chest_xray\\train\\NORMAL\\IM-0193-0001.jpeg",
         "NORMAL",
         "train",
         "data/resized/train_NORMAL_IM-0193-0001.jpeg",
         "0"
        ],
        [
         "41",
         "D:\\Projects\\Github\\X_Ray_Classification\\data\\chest_xray\\chest_xray\\train\\NORMAL\\IM-0195-0001.jpeg",
         "NORMAL",
         "train",
         "data/resized/train_NORMAL_IM-0195-0001.jpeg",
         "0"
        ],
        [
         "42",
         "D:\\Projects\\Github\\X_Ray_Classification\\data\\chest_xray\\chest_xray\\train\\NORMAL\\IM-0199-0001.jpeg",
         "NORMAL",
         "train",
         "data/resized/train_NORMAL_IM-0199-0001.jpeg",
         "0"
        ],
        [
         "43",
         "D:\\Projects\\Github\\X_Ray_Classification\\data\\chest_xray\\chest_xray\\train\\NORMAL\\IM-0201-0001.jpeg",
         "NORMAL",
         "train",
         "data/resized/train_NORMAL_IM-0201-0001.jpeg",
         "0"
        ],
        [
         "44",
         "D:\\Projects\\Github\\X_Ray_Classification\\data\\chest_xray\\chest_xray\\train\\NORMAL\\IM-0203-0001.jpeg",
         "NORMAL",
         "train",
         "data/resized/train_NORMAL_IM-0203-0001.jpeg",
         "0"
        ],
        [
         "45",
         "D:\\Projects\\Github\\X_Ray_Classification\\data\\chest_xray\\chest_xray\\train\\NORMAL\\IM-0205-0001.jpeg",
         "NORMAL",
         "train",
         "data/resized/train_NORMAL_IM-0205-0001.jpeg",
         "0"
        ],
        [
         "46",
         "D:\\Projects\\Github\\X_Ray_Classification\\data\\chest_xray\\chest_xray\\train\\NORMAL\\IM-0206-0001.jpeg",
         "NORMAL",
         "train",
         "data/resized/train_NORMAL_IM-0206-0001.jpeg",
         "0"
        ],
        [
         "47",
         "D:\\Projects\\Github\\X_Ray_Classification\\data\\chest_xray\\chest_xray\\train\\NORMAL\\IM-0207-0001.jpeg",
         "NORMAL",
         "train",
         "data/resized/train_NORMAL_IM-0207-0001.jpeg",
         "0"
        ],
        [
         "48",
         "D:\\Projects\\Github\\X_Ray_Classification\\data\\chest_xray\\chest_xray\\train\\NORMAL\\IM-0209-0001.jpeg",
         "NORMAL",
         "train",
         "data/resized/train_NORMAL_IM-0209-0001.jpeg",
         "0"
        ],
        [
         "49",
         "D:\\Projects\\Github\\X_Ray_Classification\\data\\chest_xray\\chest_xray\\train\\NORMAL\\IM-0210-0001.jpeg",
         "NORMAL",
         "train",
         "data/resized/train_NORMAL_IM-0210-0001.jpeg",
         "0"
        ]
       ],
       "shape": {
        "columns": 5,
        "rows": 5856
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Image</th>\n",
       "      <th>Class</th>\n",
       "      <th>Split</th>\n",
       "      <th>resized</th>\n",
       "      <th>clas_enc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>D:\\Projects\\Github\\X_Ray_Classification\\data\\c...</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>train</td>\n",
       "      <td>data/resized/train_NORMAL_IM-0115-0001.jpeg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D:\\Projects\\Github\\X_Ray_Classification\\data\\c...</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>train</td>\n",
       "      <td>data/resized/train_NORMAL_IM-0117-0001.jpeg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>D:\\Projects\\Github\\X_Ray_Classification\\data\\c...</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>train</td>\n",
       "      <td>data/resized/train_NORMAL_IM-0119-0001.jpeg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>D:\\Projects\\Github\\X_Ray_Classification\\data\\c...</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>train</td>\n",
       "      <td>data/resized/train_NORMAL_IM-0122-0001.jpeg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>D:\\Projects\\Github\\X_Ray_Classification\\data\\c...</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>train</td>\n",
       "      <td>data/resized/train_NORMAL_IM-0125-0001.jpeg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5851</th>\n",
       "      <td>D:\\Projects\\Github\\X_Ray_Classification\\data\\c...</td>\n",
       "      <td>PNEUMONIA</td>\n",
       "      <td>val</td>\n",
       "      <td>data/resized/val_PNEUMONIA_person1949_bacteria...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5852</th>\n",
       "      <td>D:\\Projects\\Github\\X_Ray_Classification\\data\\c...</td>\n",
       "      <td>PNEUMONIA</td>\n",
       "      <td>val</td>\n",
       "      <td>data/resized/val_PNEUMONIA_person1950_bacteria...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5853</th>\n",
       "      <td>D:\\Projects\\Github\\X_Ray_Classification\\data\\c...</td>\n",
       "      <td>PNEUMONIA</td>\n",
       "      <td>val</td>\n",
       "      <td>data/resized/val_PNEUMONIA_person1951_bacteria...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5854</th>\n",
       "      <td>D:\\Projects\\Github\\X_Ray_Classification\\data\\c...</td>\n",
       "      <td>PNEUMONIA</td>\n",
       "      <td>val</td>\n",
       "      <td>data/resized/val_PNEUMONIA_person1952_bacteria...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5855</th>\n",
       "      <td>D:\\Projects\\Github\\X_Ray_Classification\\data\\c...</td>\n",
       "      <td>PNEUMONIA</td>\n",
       "      <td>val</td>\n",
       "      <td>data/resized/val_PNEUMONIA_person1954_bacteria...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5856 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Image      Class  Split  \\\n",
       "0     D:\\Projects\\Github\\X_Ray_Classification\\data\\c...     NORMAL  train   \n",
       "1     D:\\Projects\\Github\\X_Ray_Classification\\data\\c...     NORMAL  train   \n",
       "2     D:\\Projects\\Github\\X_Ray_Classification\\data\\c...     NORMAL  train   \n",
       "3     D:\\Projects\\Github\\X_Ray_Classification\\data\\c...     NORMAL  train   \n",
       "4     D:\\Projects\\Github\\X_Ray_Classification\\data\\c...     NORMAL  train   \n",
       "...                                                 ...        ...    ...   \n",
       "5851  D:\\Projects\\Github\\X_Ray_Classification\\data\\c...  PNEUMONIA    val   \n",
       "5852  D:\\Projects\\Github\\X_Ray_Classification\\data\\c...  PNEUMONIA    val   \n",
       "5853  D:\\Projects\\Github\\X_Ray_Classification\\data\\c...  PNEUMONIA    val   \n",
       "5854  D:\\Projects\\Github\\X_Ray_Classification\\data\\c...  PNEUMONIA    val   \n",
       "5855  D:\\Projects\\Github\\X_Ray_Classification\\data\\c...  PNEUMONIA    val   \n",
       "\n",
       "                                                resized  clas_enc  \n",
       "0           data/resized/train_NORMAL_IM-0115-0001.jpeg         0  \n",
       "1           data/resized/train_NORMAL_IM-0117-0001.jpeg         0  \n",
       "2           data/resized/train_NORMAL_IM-0119-0001.jpeg         0  \n",
       "3           data/resized/train_NORMAL_IM-0122-0001.jpeg         0  \n",
       "4           data/resized/train_NORMAL_IM-0125-0001.jpeg         0  \n",
       "...                                                 ...       ...  \n",
       "5851  data/resized/val_PNEUMONIA_person1949_bacteria...         1  \n",
       "5852  data/resized/val_PNEUMONIA_person1950_bacteria...         1  \n",
       "5853  data/resized/val_PNEUMONIA_person1951_bacteria...         1  \n",
       "5854  data/resized/val_PNEUMONIA_person1952_bacteria...         1  \n",
       "5855  data/resized/val_PNEUMONIA_person1954_bacteria...         1  \n",
       "\n",
       "[5856 rows x 5 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "49523835",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "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",
      "image/png": "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",
      "text/plain": [
       "<PIL.JpegImagePlugin.JpegImageFile image mode=L size=128x128>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i = data_map['resized'][1]\n",
    "Image.open(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a386022d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "86e3efe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class XrayDataset(Dataset):\n",
    "\n",
    "    def __init__(self, df_split, transform):\n",
    "\n",
    "        self.df_split = df_split\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df_split)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        img_path = self.df_split.iloc[index][\"resized\"]\n",
    "\n",
    "        clas = self.df_split.iloc[index][\"clas_enc\"]\n",
    "\n",
    "        img = Image.open(img_path).convert(\"L\") #converting to grayscale\n",
    "\n",
    "        img_trans = self.transform(img)\n",
    "\n",
    "        return img_trans, clas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "031be572",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = XrayDataset(data_map[data_map['Split'] == 'train'], transform=transforms.ToTensor())\n",
    "val_dataset = XrayDataset(data_map[data_map['Split'] == 'val'], transform=transforms.ToTensor())\n",
    "test_dataset = XrayDataset(data_map[data_map['Split'] == 'test'], transform=transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8e3f8966",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[0.4314, 0.4118, 0.4902,  ..., 0.0510, 0.0549, 0.0588],\n",
       "          [0.3765, 0.4706, 0.4314,  ..., 0.1059, 0.1137, 0.1176],\n",
       "          [0.3882, 0.4784, 0.4235,  ..., 0.1843, 0.1922, 0.2000],\n",
       "          ...,\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]]]),\n",
       " np.int64(0))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5a907b1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "08bfd32e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.resnet50(weights = models.ResNet50_Weights.IMAGENET1K_V2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d40629fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=2048, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " models.resnet50(weights = models.ResNet50_Weights.IMAGENET1K_V2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dccd6613",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'num_ftrs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mnum_ftrs\u001b[49m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'num_ftrs' is not defined"
     ]
    }
   ],
   "source": [
    "num_ftrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4e624903",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.conv1 = nn.Conv2d(1, 64, kernel_size=(4, 4), stride=(2, 2), padding=(3, 3), bias=False)\n",
    "num_ftrs = model.fc.in_features\n",
    "model.fc = nn.Linear(in_features=num_ftrs, out_features=2, bias=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "df889008",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "98622a1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5ead988f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.8\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.version.cuda)  # Should show 12.8 or your installed version\n",
    "print(torch.cuda.is_available())  # Should return True if CUDA is available\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "499ea00b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure that model and model2 are properly moved to the device without redefinition\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0c1871b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7e8cc2c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "class Trainer:\n",
    "    def __init__(self, model, criterion, optimizer, device, early_stopping, \n",
    "                 model_save_path=\"models/best_model4.pth\", epoch_weights_dir=\"weights\",\n",
    "                 test_loader=None):\n",
    "        self.model = model\n",
    "        self.criterion = criterion\n",
    "        self.optimizer = optimizer\n",
    "        self.device = device\n",
    "        self.early_stopping = early_stopping\n",
    "        self.model_save_path = model_save_path\n",
    "        self.epoch_weights_dir = epoch_weights_dir\n",
    "        self.test_loader = test_loader\n",
    "\n",
    "        self.train_losses = []\n",
    "        self.val_losses = []\n",
    "        self.test_losses = []\n",
    "        self.train_accs = []\n",
    "        self.val_accs = []\n",
    "        self.test_accs = []\n",
    "\n",
    "        os.makedirs(os.path.dirname(model_save_path), exist_ok=True)\n",
    "        os.makedirs(epoch_weights_dir, exist_ok=True)\n",
    "        \n",
    "\n",
    "    def train_epoch(self, train_loader, epoch_desc=\"Training\"):\n",
    "        self.model.train()\n",
    "        running_loss, correct, total = 0.0, 0, 0\n",
    "        pbar = tqdm(train_loader, desc=epoch_desc)\n",
    "\n",
    "        for images, labels in pbar:\n",
    "            images, labels = images.to(self.device), labels.to(self.device)\n",
    "            self.optimizer.zero_grad()\n",
    "            outputs = self.model(images)\n",
    "            loss_value = self.criterion(outputs, labels)\n",
    "            loss_value.backward()\n",
    "            self.optimizer.step()\n",
    "\n",
    "            running_loss += loss_value.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            pbar.set_postfix({'loss': running_loss / (pbar.n + 1), 'acc': correct / total})\n",
    "\n",
    "        return running_loss / len(train_loader), correct / total\n",
    "\n",
    "    def validate_epoch(self, val_loader):\n",
    "        self.model.eval()\n",
    "        val_loss, correct, total = 0.0, 0, 0\n",
    "        with torch.no_grad():\n",
    "            for images, labels in tqdm(val_loader, desc=\"Validation\"):\n",
    "                images, labels = images.to(self.device), labels.to(self.device)\n",
    "                outputs = self.model(images)\n",
    "                loss_value = self.criterion(outputs, labels)\n",
    "                val_loss += loss_value.item()\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "        return val_loss / len(val_loader), correct / total\n",
    "\n",
    "    def test_epoch(self, test_loader):\n",
    "        self.model.eval()\n",
    "        test_loss, correct, total = 0.0, 0, 0\n",
    "        with torch.no_grad():\n",
    "            for images, labels in tqdm(test_loader, desc=\"Testing\"):\n",
    "                images, labels = images.to(self.device), labels.to(self.device)\n",
    "                outputs = self.model(images)\n",
    "                loss_value = self.criterion(outputs, labels)\n",
    "                test_loss += loss_value.item()\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "        return test_loss / len(test_loader), correct / total\n",
    "\n",
    "    def run_training(self, train_loader, val_loader, num_epochs=30):\n",
    "        best_val_acc = 0.0  # Track best accuracy\n",
    "\n",
    "        for epoch in range(num_epochs):\n",
    "            torch.cuda.empty_cache()\n",
    "            print(f\"\\n=== Epoch [{epoch+1}/{num_epochs}] ===\")\n",
    "\n",
    "            train_loss, train_acc = self.train_epoch(train_loader, epoch_desc=f\"Epoch {epoch+1}\")\n",
    "            val_loss, val_acc = self.validate_epoch(val_loader)\n",
    "\n",
    "            self.train_losses.append(train_loss)\n",
    "            self.train_accs.append(train_acc)\n",
    "            self.val_losses.append(val_loss)\n",
    "            self.val_accs.append(val_acc)\n",
    "\n",
    "            print(f\"Train Loss: {train_loss:.4f}, Accuracy: {train_acc:.4f}\")\n",
    "            print(f\"Validation Loss: {val_loss:.4f}, Accuracy: {val_acc:.4f}\")\n",
    "\n",
    "            if self.test_loader:\n",
    "                test_loss, test_acc = self.test_epoch(self.test_loader)\n",
    "                self.test_losses.append(test_loss)\n",
    "                self.test_accs.append(test_acc)\n",
    "                print(f\"Test Loss: {test_loss:.4f}, Accuracy: {test_acc:.4f}\")\n",
    "\n",
    "            # Save current epoch weights\n",
    "            torch.save(self.model.state_dict(), os.path.join(self.epoch_weights_dir, f\"epoch_{epoch+1}_weights.pth\"))\n",
    "\n",
    "            # Save best model based on validation accuracy\n",
    "            if val_acc > best_val_acc:\n",
    "                best_val_acc = val_acc\n",
    "                print(f\"Validation accuracy improved to {val_acc:.4f}. Saving best model.\")\n",
    "                torch.save(self.model.state_dict(), self.model_save_path)\n",
    "\n",
    "            # Early stopping based on validation loss\n",
    "            if self.early_stopping(val_acc):\n",
    "                print(\"Early stopping triggered.\")\n",
    "                break\n",
    "\n",
    "    def evaluate_model(self, data_loader):\n",
    "        return self.test_epoch(data_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2e9dbda6",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'EarlyStopping' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[24], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mAdam(model\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.0001\u001b[39m)\n\u001b[0;32m      4\u001b[0m criterion \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mCrossEntropyLoss()\n\u001b[1;32m----> 5\u001b[0m early_stopping \u001b[38;5;241m=\u001b[39m \u001b[43mEarlyStopping\u001b[49m(patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m7\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m      7\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Trainer(\n\u001b[0;32m      8\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[0;32m      9\u001b[0m     criterion\u001b[38;5;241m=\u001b[39mcriterion,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     15\u001b[0m     test_loader\u001b[38;5;241m=\u001b[39mtest_loader  \u001b[38;5;66;03m# Include test loader if you want test each epoch\u001b[39;00m\n\u001b[0;32m     16\u001b[0m )\n\u001b[0;32m     18\u001b[0m trainer\u001b[38;5;241m.\u001b[39mrun_training(train_loader, val_loader, num_epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m30\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'EarlyStopping' is not defined"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "#early_stopping\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "early_stopping = EarlyStopping(patience=7, verbose=True)\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    criterion=criterion,\n",
    "    optimizer=optimizer,\n",
    "    device=device,\n",
    "    early_stopping=early_stopping,\n",
    "    model_save_path=\"models/best_model4.pth\",\n",
    "    epoch_weights_dir=\"weights\",\n",
    "    test_loader=test_loader  # Include test loader if you want test each epoch\n",
    ")\n",
    "\n",
    "trainer.run_training(train_loader, val_loader, num_epochs=30)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "07d45de5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "epochs = range(1, len(trainer.train_losses) + 1)\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs, trainer.train_losses, label='Train Loss')\n",
    "plt.plot(epochs, trainer.val_losses, label='Validation Loss')\n",
    "if trainer.test_losses:\n",
    "    plt.plot(epochs, trainer.test_losses, label='Test Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.title('Losses')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs, trainer.train_accs, label='Train Accuracy')\n",
    "plt.plot(epochs, trainer.val_accs, label='Validation Accuracy')\n",
    "if trainer.test_accs:\n",
    "    plt.plot(epochs, trainer.test_accs, label='Test Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.title('Accuracies')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "5cb2e4cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import models\n",
    "\n",
    "def evaluate_all_models(model_dir, test_loader, device, trainer):\n",
    "    model_files = [f for f in os.listdir(model_dir) if f.endswith('.pth')]\n",
    "    accuracies = {}\n",
    "\n",
    "    for model_file in model_files:\n",
    "        model_path = os.path.join(model_dir, model_file)\n",
    "        print(f\"Evaluating {model_file}...\")\n",
    "\n",
    "        # Create a fresh resnet50 model\n",
    "        model = models.resnet50(weights=None)\n",
    "\n",
    "        # Modify the first conv layer to accept 1 channel (grayscale images)\n",
    "        model.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "\n",
    "        # Modify the last fully connected layer for binary classification\n",
    "        num_ftrs = model.fc.in_features\n",
    "        model.fc = nn.Linear(in_features=num_ftrs, out_features=2, bias=True)\n",
    "\n",
    "        # Load the model weights\n",
    "        model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "        model.to(device)\n",
    "\n",
    "        # Evaluate the model\n",
    "        test_loss, test_acc = trainer.evaluate_model(model, test_loader)\n",
    "        accuracies[model_file] = test_acc\n",
    "        print(f\"Test Accuracy: {test_acc:.4f}\")\n",
    "\n",
    "    return accuracies\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8efbb598",
   "metadata": {},
   "source": [
    "Epoch 6 has the best weights with:  Validation Loss: 0.0159, Validation Accuracy: 1.0000 ,Train Loss: 0.0169, Train Accuracy: 0.9931\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "87ccd043",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(\"data/lbl_enoder.pkl\", \"wb\") as f:\n",
    "    pickle.dump(lbl_encoder, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f9e80701",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Image",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Class",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Split",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "resized",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "clas_enc",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "6e27f071-db62-43ac-9020-f096fa0fddcb",
       "rows": [
        [
         "0",
         "D:\\Projects\\Github\\X_Ray_Classification\\data\\chest_xray\\chest_xray\\train\\NORMAL\\IM-0115-0001.jpeg",
         "NORMAL",
         "train",
         "data/resized/train_NORMAL_IM-0115-0001.jpeg",
         "0"
        ],
        [
         "1",
         "D:\\Projects\\Github\\X_Ray_Classification\\data\\chest_xray\\chest_xray\\train\\NORMAL\\IM-0117-0001.jpeg",
         "NORMAL",
         "train",
         "data/resized/train_NORMAL_IM-0117-0001.jpeg",
         "0"
        ],
        [
         "2",
         "D:\\Projects\\Github\\X_Ray_Classification\\data\\chest_xray\\chest_xray\\train\\NORMAL\\IM-0119-0001.jpeg",
         "NORMAL",
         "train",
         "data/resized/train_NORMAL_IM-0119-0001.jpeg",
         "0"
        ],
        [
         "3",
         "D:\\Projects\\Github\\X_Ray_Classification\\data\\chest_xray\\chest_xray\\train\\NORMAL\\IM-0122-0001.jpeg",
         "NORMAL",
         "train",
         "data/resized/train_NORMAL_IM-0122-0001.jpeg",
         "0"
        ],
        [
         "4",
         "D:\\Projects\\Github\\X_Ray_Classification\\data\\chest_xray\\chest_xray\\train\\NORMAL\\IM-0125-0001.jpeg",
         "NORMAL",
         "train",
         "data/resized/train_NORMAL_IM-0125-0001.jpeg",
         "0"
        ]
       ],
       "shape": {
        "columns": 5,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Image</th>\n",
       "      <th>Class</th>\n",
       "      <th>Split</th>\n",
       "      <th>resized</th>\n",
       "      <th>clas_enc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>D:\\Projects\\Github\\X_Ray_Classification\\data\\c...</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>train</td>\n",
       "      <td>data/resized/train_NORMAL_IM-0115-0001.jpeg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D:\\Projects\\Github\\X_Ray_Classification\\data\\c...</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>train</td>\n",
       "      <td>data/resized/train_NORMAL_IM-0117-0001.jpeg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>D:\\Projects\\Github\\X_Ray_Classification\\data\\c...</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>train</td>\n",
       "      <td>data/resized/train_NORMAL_IM-0119-0001.jpeg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>D:\\Projects\\Github\\X_Ray_Classification\\data\\c...</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>train</td>\n",
       "      <td>data/resized/train_NORMAL_IM-0122-0001.jpeg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>D:\\Projects\\Github\\X_Ray_Classification\\data\\c...</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>train</td>\n",
       "      <td>data/resized/train_NORMAL_IM-0125-0001.jpeg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Image   Class  Split  \\\n",
       "0  D:\\Projects\\Github\\X_Ray_Classification\\data\\c...  NORMAL  train   \n",
       "1  D:\\Projects\\Github\\X_Ray_Classification\\data\\c...  NORMAL  train   \n",
       "2  D:\\Projects\\Github\\X_Ray_Classification\\data\\c...  NORMAL  train   \n",
       "3  D:\\Projects\\Github\\X_Ray_Classification\\data\\c...  NORMAL  train   \n",
       "4  D:\\Projects\\Github\\X_Ray_Classification\\data\\c...  NORMAL  train   \n",
       "\n",
       "                                       resized  clas_enc  \n",
       "0  data/resized/train_NORMAL_IM-0115-0001.jpeg         0  \n",
       "1  data/resized/train_NORMAL_IM-0117-0001.jpeg         0  \n",
       "2  data/resized/train_NORMAL_IM-0119-0001.jpeg         0  \n",
       "3  data/resized/train_NORMAL_IM-0122-0001.jpeg         0  \n",
       "4  data/resized/train_NORMAL_IM-0125-0001.jpeg         0  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_map.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "832768bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['train', 'test', 'val'], dtype=object)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_map['Split'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6ec7bb6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_map['clas_enc'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "55ba6e97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "clas_enc\n",
       "1    4273\n",
       "0    1583\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_map['clas_enc'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "898f1525",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = r\"D:\\Projects\\github\\X_Ray_Classification\\models\\best_model2.pth\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fd1eebb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted class: PNEUMONIA\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torchvision import models, transforms\n",
    "from torch import nn\n",
    "from PIL import Image\n",
    "\n",
    "# Load label encoder\n",
    "import pickle\n",
    "with open(\"D:\\Projects\\github\\X_Ray_Classification\\data\\lbl_encoder.pkl\", \"rb\") as f:\n",
    "    lbl_encoder = pickle.load(f)\n",
    "\n",
    "# Load the model architecture\n",
    "model = models.resnet50(weights=None)  # no weights because we will load ours\n",
    "model.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "num_ftrs = model.fc.in_features\n",
    "model.fc = nn.Linear(num_ftrs, 2)\n",
    "\n",
    "# Load saved weights\n",
    "model.load_state_dict(torch.load(r\"D:\\Projects\\github\\X_Ray_Classification\\models\\best_model.pth\", map_location=\"cuda\"))\n",
    "model.eval()\n",
    "model.to(\"cuda\")  # or \"cpu\" if you're not using GPU\n",
    "\n",
    "# Preprocess the image\n",
    "img_path = r\"D:\\Projects\\github\\X_Ray_Classification\\data\\chest_xray\\chest_xray\\resized\\train_PNEUMONIA_person529_bacteria_2229.jpeg\"\n",
    "img = Image.open(img_path).convert(\"L\")  # convert to grayscale\n",
    "img_tensor = transforms.ToTensor()(img).unsqueeze(0).to(\"cuda\")  # add batch dimension\n",
    "\n",
    "# Run prediction\n",
    "with torch.no_grad():\n",
    "    outputs = model(img_tensor)\n",
    "    predicted_class = torch.argmax(outputs, dim=1).item()\n",
    "\n",
    "# Decode label\n",
    "predicted_label = lbl_encoder.inverse_transform([predicted_class])[0]\n",
    "print(f\"Predicted class: {predicted_label}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c9b92156",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import models\n",
    "from torch import nn\n",
    "\n",
    "def evaluate_model_on_test(model_path, test_loader, device=\"cuda\"):\n",
    "    # Recreate the same model architecture\n",
    "    model = models.resnet50(weights=None)\n",
    "    model.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "    num_ftrs = model.fc.in_features\n",
    "    model.fc = nn.Linear(num_ftrs, 2)\n",
    "\n",
    "    # Load the saved weights\n",
    "    model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    accuracy = correct / total\n",
    "    print(f\"Test Accuracy: {accuracy:.4f}\")\n",
    "    return accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "03b659e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def infer(img_path):\n",
    "    # Load the model architecture   \n",
    "    model = models.resnet50(weights=None)\n",
    "    model.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "    num_ftrs = model.fc.in_features\n",
    "    model.fc = nn.Linear(num_ftrs, 2)\n",
    "    model.load_state_dict(torch.load(r\"D:\\Projects\\github\\X_Ray_Classification\\models\\best_model.pth\", map_location=\"cuda\"))\n",
    "    model.eval()\n",
    "    model.to(\"cuda\")  # or \"cpu\" if you're not using GPU\n",
    "    img = Image.open(img_path).convert(\"L\")  # convert to grayscale\n",
    "    img = transforms.ToTensor()(img).unsqueeze(0).to(\"cuda\")\n",
    "    with torch.no_grad():\n",
    "        output = model(img)\n",
    "        argmax = torch.argmax(output, dim=1).item()\n",
    "        predicted_class = lbl_encoder.inverse_transform([argmax])[0]\n",
    "    return predicted_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "832ccece",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'PNEUMONIA'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "infer(r\"D:\\Projects\\github\\X_Ray_Classification\\data\\chest_xray\\chest_xray\\resized\\train_PNEUMONIA_person529_bacteria_2229.jpeg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3383bdf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.8413\n",
      "best_model2 0.8413461538461539\n",
      "---------------------------------------\n",
      "Test Accuracy: 0.8429\n",
      "best_model 0.842948717948718\n",
      "---------------------------------------\n",
      "Test Accuracy: 0.8125\n",
      "best_model3 0.8125\n",
      "---------------------------------------\n",
      "Test Accuracy: 0.8013\n",
      "best_model4 0.8012820512820513\n",
      "---------------------------------------\n",
      "Test Accuracy: 0.7644\n",
      "best_model_resnet50_model 0.7644230769230769\n"
     ]
    }
   ],
   "source": [
    "print(\"best_model2\",evaluate_model_on_test(r\"D:\\Projects\\github\\X_Ray_Classification\\models\\best_model2.pth\", test_loader, device=\"cuda\"))\n",
    "print(\"---------------------------------------\")\n",
    "print(\"best_model\",evaluate_model_on_test(r\"D:\\Projects\\github\\X_Ray_Classification\\models\\best_model.pth\", test_loader, device=\"cuda\"))\n",
    "print(\"---------------------------------------\")\n",
    "print(\"best_model3\",evaluate_model_on_test(r\"D:\\Projects\\github\\X_Ray_Classification\\models\\best_model3.pth\", test_loader, device=\"cuda\"))\n",
    "print(\"---------------------------------------\")\n",
    "print(\"best_model4\",evaluate_model_on_test(r\"D:\\Projects\\github\\X_Ray_Classification\\models\\best_model4.pth\", test_loader, device=\"cuda\"))\n",
    "print(\"---------------------------------------\")\n",
    "print(\"best_model_resnet50_model\",evaluate_model_on_test(r\"D:\\Projects\\github\\X_Ray_Classification\\models\\best_resnet50_model.pth\", test_loader, device=\"cuda\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7b741c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "a50d0889",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'str' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[72], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m img \u001b[38;5;241m=\u001b[39m Image\u001b[38;5;241m.\u001b[39mopen(img_path)\u001b[38;5;241m.\u001b[39mconvert(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mL\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      3\u001b[0m img_trans \u001b[38;5;241m=\u001b[39m  transforms\u001b[38;5;241m.\u001b[39mToTensor()(img)\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m----> 4\u001b[0m preds \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg_trans\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m class_indx \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39margmax(preds)\u001b[38;5;241m.\u001b[39mitem()\n\u001b[0;32m      6\u001b[0m class_indx\n",
      "\u001b[1;31mTypeError\u001b[0m: 'str' object is not callable"
     ]
    }
   ],
   "source": [
    "img_path = r\"D:\\Projects\\github\\X_Ray_Classification\\data\\chest_xray\\chest_xray\\resized\\train_PNEUMONIA_person529_bacteria_2229.jpeg\" \n",
    "img = Image.open(img_path).convert(\"L\")\n",
    "img_trans =  transforms.ToTensor()(img).unsqueeze(0).to(device)\n",
    "preds = model(img_trans)\n",
    "class_indx = torch.argmax(preds).item()\n",
    "class_indx\n",
    "lbl_encoder.inverse_transform([class_indx])[0]\n",
    "#img_trans = transforms.Compose([transforms.Resize((128,128)), transforms.ToTensor()]).to\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e64552c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "lbl_encoder = LabelEncoder()\n",
    "data_map[\"clas_enc\"] = lbl_encoder.fit_transform(data_map[\"Class\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d241fc7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model weights from D:\\Projects\\github\\X_Ray_Classification\\weights\\epoch_6_weights.pth\n",
      "Example image path: data/resized/test_NORMAL_IM-0006-0001.jpeg\n",
      "Actual class: NORMAL\n",
      "Predicted class: PNEUMONIA\n",
      "Prediction probabilities: [0.14258128 0.8574188 ]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "# Load the label encoder\n",
    "with open(\"D:\\Projects\\github\\X_Ray_Classification\\data\\lbl_encoder.pkl\", \"rb\") as f:\n",
    "    lbl_encoder = pickle.load(f)\n",
    "\n",
    "# Define the inference function\n",
    "def predict_xray_class(model, image_path, device, label_encoder):\n",
    "    \"\"\"\n",
    "    Predicts the class of a single X-ray image.\n",
    "\n",
    "    Args:\n",
    "        model: The trained PyTorch model.\n",
    "        image_path (str): The path to the input image.\n",
    "        device (torch.device): The device to use for inference (e.g., 'cuda' or 'cpu').\n",
    "        label_encoder: The fitted LabelEncoder object.\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple containing the predicted class name and the prediction probabilities.\n",
    "    \"\"\"\n",
    "    model.eval() # Set the model to evaluation mode\n",
    "\n",
    "    # Define the image transformation (should match the training transformation)\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        # Add any other necessary transformations (e.g., resizing if not already done)\n",
    "    ])\n",
    "\n",
    "    # Load and preprocess the image\n",
    "    img = Image.open(image_path).convert(\"L\") # Convert to grayscale\n",
    "    img_tensor = transform(img).unsqueeze(0) # Add batch dimension\n",
    "\n",
    "    # Move the image tensor to the device\n",
    "    img_tensor = img_tensor.to(device)\n",
    "\n",
    "    # Perform inference\n",
    "    with torch.no_grad():\n",
    "        outputs = model(img_tensor)\n",
    "        probabilities = torch.softmax(outputs, dim=1)\n",
    "        _, predicted_class_index = torch.max(outputs, 1)\n",
    "\n",
    "    # Get the predicted class name\n",
    "    predicted_class_name = label_encoder.inverse_transform(predicted_class_index.cpu())[0]\n",
    "\n",
    "    return predicted_class_name, probabilities.cpu().numpy()[0]\n",
    "\n",
    "# --- Example Usage ---\n",
    "# Assuming 'model' is your trained model loaded with the best weights\n",
    "# Assuming 'device' is defined (e.g., torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"))\n",
    "\n",
    "# Load the model weights from epoch 6\n",
    "epoch_6_weights_path = \"D:\\Projects\\github\\X_Ray_Classification\\weights\\epoch_6_weights.pth\"\n",
    "print(f\"Loading model weights from {epoch_6_weights_path}\")\n",
    "model.load_state_dict(torch.load(epoch_6_weights_path)) # Using 'model'\n",
    "model.to(device) # Ensure the loaded model is on the correct device\n",
    "\n",
    "\n",
    "# Get an example image path from the test set\n",
    "# Note: data_map needs to be defined in a previous cell for this to work\n",
    "example_image_path = data_map[data_map['Split'] == 'test'].iloc[3]['resized']\n",
    "actual_class = data_map[data_map['Split'] == 'test'].iloc[3]['Class']\n",
    "\n",
    "print(f\"Example image path: {example_image_path}\")\n",
    "print(f\"Actual class: {actual_class}\")\n",
    "\n",
    "# Perform prediction\n",
    "predicted_class, probabilities = predict_xray_class(model, example_image_path, device, lbl_encoder)\n",
    "\n",
    "print(f\"Predicted class: {predicted_class}\")\n",
    "print(f\"Prediction probabilities: {probabilities}\")\n",
    "\n",
    "# You can repeat this for other images in the test set to evaluate the model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "61e7ebe7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 78 %\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for i, (images, labels) in enumerate(test_loader):\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        if i == 0:\n",
    "            correct = 0\n",
    "            total = 0\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "    print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
    "        100 * correct / total))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "e2df2191",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'data/resized/test_NORMAL_IM-0011-0001-0001.jpeg'"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_map[data_map['Split'] == 'test'].iloc[7]['resized']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "91fd5f5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suppose your DataFrame has a column 'Class' with string labels\n",
    "class_names = data_map['Class']  # Replace with your actual column name\n",
    "lbl_encoder = LabelEncoder()\n",
    "lbl_encoder.fit(class_names)\n",
    "\n",
    "# Save the LabelEncoder to a file\n",
    "with open(\"data/lbl_encoder.pkl\", \"wb\") as f:\n",
    "    pickle.dump(lbl_encoder, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ee3fce0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Image",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Class",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Split",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "resized",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "clas_enc",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "b2a5880c-8860-4fa4-98f6-685e9fe1b6e5",
       "rows": [
        [
         "0",
         "D:\\Projects\\Github\\X_Ray_Classification\\data\\chest_xray\\chest_xray\\train\\NORMAL\\IM-0115-0001.jpeg",
         "NORMAL",
         "train",
         "data/resized/train_NORMAL_IM-0115-0001.jpeg",
         "0"
        ],
        [
         "1",
         "D:\\Projects\\Github\\X_Ray_Classification\\data\\chest_xray\\chest_xray\\train\\NORMAL\\IM-0117-0001.jpeg",
         "NORMAL",
         "train",
         "data/resized/train_NORMAL_IM-0117-0001.jpeg",
         "0"
        ],
        [
         "2",
         "D:\\Projects\\Github\\X_Ray_Classification\\data\\chest_xray\\chest_xray\\train\\NORMAL\\IM-0119-0001.jpeg",
         "NORMAL",
         "train",
         "data/resized/train_NORMAL_IM-0119-0001.jpeg",
         "0"
        ],
        [
         "3",
         "D:\\Projects\\Github\\X_Ray_Classification\\data\\chest_xray\\chest_xray\\train\\NORMAL\\IM-0122-0001.jpeg",
         "NORMAL",
         "train",
         "data/resized/train_NORMAL_IM-0122-0001.jpeg",
         "0"
        ],
        [
         "4",
         "D:\\Projects\\Github\\X_Ray_Classification\\data\\chest_xray\\chest_xray\\train\\NORMAL\\IM-0125-0001.jpeg",
         "NORMAL",
         "train",
         "data/resized/train_NORMAL_IM-0125-0001.jpeg",
         "0"
        ]
       ],
       "shape": {
        "columns": 5,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Image</th>\n",
       "      <th>Class</th>\n",
       "      <th>Split</th>\n",
       "      <th>resized</th>\n",
       "      <th>clas_enc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>D:\\Projects\\Github\\X_Ray_Classification\\data\\c...</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>train</td>\n",
       "      <td>data/resized/train_NORMAL_IM-0115-0001.jpeg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D:\\Projects\\Github\\X_Ray_Classification\\data\\c...</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>train</td>\n",
       "      <td>data/resized/train_NORMAL_IM-0117-0001.jpeg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>D:\\Projects\\Github\\X_Ray_Classification\\data\\c...</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>train</td>\n",
       "      <td>data/resized/train_NORMAL_IM-0119-0001.jpeg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>D:\\Projects\\Github\\X_Ray_Classification\\data\\c...</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>train</td>\n",
       "      <td>data/resized/train_NORMAL_IM-0122-0001.jpeg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>D:\\Projects\\Github\\X_Ray_Classification\\data\\c...</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>train</td>\n",
       "      <td>data/resized/train_NORMAL_IM-0125-0001.jpeg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Image   Class  Split  \\\n",
       "0  D:\\Projects\\Github\\X_Ray_Classification\\data\\c...  NORMAL  train   \n",
       "1  D:\\Projects\\Github\\X_Ray_Classification\\data\\c...  NORMAL  train   \n",
       "2  D:\\Projects\\Github\\X_Ray_Classification\\data\\c...  NORMAL  train   \n",
       "3  D:\\Projects\\Github\\X_Ray_Classification\\data\\c...  NORMAL  train   \n",
       "4  D:\\Projects\\Github\\X_Ray_Classification\\data\\c...  NORMAL  train   \n",
       "\n",
       "                                       resized  clas_enc  \n",
       "0  data/resized/train_NORMAL_IM-0115-0001.jpeg         0  \n",
       "1  data/resized/train_NORMAL_IM-0117-0001.jpeg         0  \n",
       "2  data/resized/train_NORMAL_IM-0119-0001.jpeg         0  \n",
       "3  data/resized/train_NORMAL_IM-0122-0001.jpeg         0  \n",
       "4  data/resized/train_NORMAL_IM-0125-0001.jpeg         0  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_map.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a444ba8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cv_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
